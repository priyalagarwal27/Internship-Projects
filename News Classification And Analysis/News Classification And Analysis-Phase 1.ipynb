{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time,json\n",
    "import io,os\n",
    "import re\n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.common.exceptions import NoSuchElementException,ElementNotVisibleException,StaleElementReferenceException,ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver1.exe\")\n",
    "driver.get(\"https://timesofindia.indiatimes.com/archive.cms\")\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "#Create empty lists\n",
    "date,author,vertical,headline,desc,links,news= [],[],[],[],[],[],[]\n",
    "    \n",
    "#Click not now button\n",
    "driver.find_element_by_xpath('//span[@class=\"ntfc_buttongroup\"]/a[1]').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#Click November button\n",
    "driver.find_element_by_xpath('/html/body/center/div[1]/div[3]/table[2]/tbody/tr[2]/td[1]/div[3]/table/tbody/tr[1]/td/span/div/strong/a[14]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "#Loop to fetch urls of date\n",
    "urls=driver.find_elements_by_xpath(\"/html/body/center/div[1]/div[3]/table[2]/tbody/tr[2]/td[1]/div[3]/table/tbody/tr[1]/td/span/div/table/tbody/tr/td/a\")\n",
    "for url in urls:\n",
    "    url.get_attribute('href')\n",
    "    links.append(url.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to fetch url of review inside each date\n",
    "for i in range(0,len(links)):\n",
    "    driver.get(links[i])\n",
    "    time.sleep(2)\n",
    "    urls_news=driver.find_elements_by_xpath(\"/html/body/div[1]/table[2]/tbody/tr[2]/td[1]/div[3]/table/tbody/tr[2]/td[1]/span/a\")\n",
    "    for j in range(0,20):\n",
    "        urls_news[j].get_attribute('href')\n",
    "        news.append(urls_news[j].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from each date                \n",
    "for i in range(0,len(news)):\n",
    "    driver.get(news[i])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Extracts the Headlines\n",
    "    try:\n",
    "        head= driver.find_elements_by_xpath(\"/html/body/div[1]/div[18]/div[5]/div[3]/div[1]/h1\")\n",
    "        headline.append(head[0].text)\n",
    "    except :\n",
    "        headline.append(\"-\")\n",
    "        \n",
    "    # Extracts the Date\n",
    "    try:\n",
    "        pub_date = driver.find_elements_by_xpath(\"/html/body/div[1]/div[18]/div[5]/div[3]/div[1]/div[2]/div[3]\")\n",
    "        date.append(pub_date[0].text.replace(\"Created:\",\" \"))\n",
    "    except:\n",
    "        date.append(None)\n",
    "\n",
    "    # Extracts the Vertical\n",
    "    try:\n",
    "        Vertical = driver.find_elements_by_xpath(\"/html/body/div[1]/div[16]/div/div/ol/li[2]/a/span\")\n",
    "        vertical.append(Vertical[0].text)\n",
    "    except:\n",
    "        vertical.append(None)\n",
    "        \n",
    "    # Extracts the Author\n",
    "    try:\n",
    "        Author = driver.find_elements_by_xpath(\"/html/body/div[1]/div[18]/div[5]/div[3]/div[1]/div[2]/div[2]/a\")\n",
    "        author.append(Author[0].text)\n",
    "    except:\n",
    "        author.append(None)\n",
    "        \n",
    "    # Extracts the desc\n",
    "    try:\n",
    "        Desc = driver.find_elements_by_xpath(\"/html/body/div[1]/div[18]/div[5]/div[3]/div[2]/div[1]/div[2]/div/arttextxml/div/div\")\n",
    "        desc.append(Desc[0].text)\n",
    "    except:\n",
    "        desc.append(None)\n",
    "        \n",
    "        \n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving in dataframe            \n",
    "df=pd.DataFrame({'Date':date,\n",
    "                 'Author Name':author,\n",
    "                 'Vertical':vertical,\n",
    "                 'Headline':headline,\n",
    "                 'Description':desc}) \n",
    "#Saving in csv format\n",
    "df.to_csv('news_toi.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

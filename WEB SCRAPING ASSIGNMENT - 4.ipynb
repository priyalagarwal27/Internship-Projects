{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEB SCRAPING ASSIGNMENT - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time,json\n",
    "from PIL import Image\n",
    "import io,os\n",
    "import re\n",
    "import hashlib\n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.common.exceptions import NoSuchElementException,ElementNotVisibleException,StaleElementReferenceException,ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/ \n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Name Rank  \\\n",
      "0                            \"Baby Shark Dance\" 28     1   \n",
      "1                                   \"Despacito\" 30     2   \n",
      "2                                \"Shape of You\" 31     3   \n",
      "3                               \"See You Again\" 32     4   \n",
      "4                        \"Johny Johny Yes Papa\" 35     5   \n",
      "5    \"Masha and the Bear – Recipe for Disaster\" 36     6   \n",
      "6                                 \"Uptown Funk\" 37     7   \n",
      "7                               \"Gangnam Style\" 38     8   \n",
      "8   \"Learning Colors – Colorful Eggs on a Farm\" 40     9   \n",
      "9                                   \"Bath Song\" 41    10   \n",
      "10                \"Phonics Song with Two Words\" 42    11   \n",
      "11                                      \"Sorry\" 43    12   \n",
      "12                                      \"Sugar\" 44    13   \n",
      "13                                       \"Roar\" 45    14   \n",
      "14                             \"Counting Stars\" 46    15   \n",
      "15                          \"Thinking Out Loud\" 47    16   \n",
      "16                             \"Dame Tu Cosita\" 48    17   \n",
      "17                               \"Shake It Off\" 49    18   \n",
      "18                                      \"Faded\" 50    19   \n",
      "19                                    \"Lean On\" 51    20   \n",
      "20                                   \"Bailando\" 52    21   \n",
      "21                                 \"Dark Horse\" 53    22   \n",
      "22                             \"Girls Like You\" 54    23   \n",
      "23                                 \"Let Her Go\" 55    24   \n",
      "24                                   \"Mi Gente\" 56    25   \n",
      "25                                      \"Hello\" 57    26   \n",
      "26                                    \"Perfect\" 58    27   \n",
      "27           \"Waka Waka (This Time for Africa)\" 59    28   \n",
      "28                                \"Blank Space\" 60    29   \n",
      "29                                   \"Chantaje\" 61    30   \n",
      "\n",
      "                                               Artist               Date Views  \n",
      "0                      Pinkfong Kids' Songs & Stories      June 17, 2016  7.91  \n",
      "1                   Luis Fonsi featuring Daddy Yankee   January 12, 2017  7.20  \n",
      "2                                          Ed Sheeran   January 30, 2017  5.18  \n",
      "3                  Wiz Khalifa featuring Charlie Puth      April 6, 2015  4.96  \n",
      "4                                         LooLoo Kids    October 8, 2016  4.77  \n",
      "5                                          Get Movies   January 31, 2012  4.41  \n",
      "6                    Mark Ronson featuring Bruno Mars  November 19, 2014  4.09  \n",
      "7                                                 Psy      July 15, 2012  3.97  \n",
      "8                                         Miroshka TV  February 27, 2018  3.69  \n",
      "9                          Cocomelon – Nursery Rhymes        May 2, 2018  3.64  \n",
      "10                                          ChuChu TV      March 6, 2014  3.53  \n",
      "11                                      Justin Bieber   October 22, 2015  3.40  \n",
      "12                                           Maroon 5   January 14, 2015  3.39  \n",
      "13                                         Katy Perry  September 5, 2013  3.27  \n",
      "14                                        OneRepublic       May 31, 2013  3.19  \n",
      "15                                         Ed Sheeran    October 7, 2014  3.18  \n",
      "16                    El Chombo featuring Cutty Ranks      April 5, 2018  3.11  \n",
      "17                                       Taylor Swift    August 18, 2014  3.02  \n",
      "18                                        Alan Walker   December 3, 2015  2.98  \n",
      "19              Major Lazer and DJ Snake featuring MØ     March 22, 2015  2.97  \n",
      "20  Enrique Iglesias featuring Descemer Bueno and ...     April 11, 2014  2.97  \n",
      "21                       Katy Perry featuring Juicy J  February 20, 2014  2.97  \n",
      "22                         Maroon 5 featuring Cardi B       May 31, 2018  2.96  \n",
      "23                                          Passenger      July 25, 2012  2.91  \n",
      "24                         J Balvin and Willy William      June 29, 2017  2.86  \n",
      "25                                              Adele   October 22, 2015  2.79  \n",
      "26                                         Ed Sheeran   November 9, 2017  2.74  \n",
      "27                    Shakira featuring Freshlyground       June 4, 2010  2.74  \n",
      "28                                       Taylor Swift  November 10, 2014  2.72  \n",
      "29                           Shakira featuring Maluma  November 18, 2016  2.62  \n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "time.sleep(2)\n",
    "\n",
    "#Scroll upto target location\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "target = driver.find_element_by_xpath('/html/body/div[3]/div[3]/div[5]/div[1]/h2[2]/span')\n",
    "target.location_once_scrolled_into_view \n",
    "time.sleep(3)\n",
    "\n",
    "#empty list\n",
    "rank,name,artist,date,views=[],[],[],[],[]\n",
    "\n",
    "#Scrape required details \n",
    "Name = driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]/tbody/tr/td[2]\")\n",
    "for i in Name:\n",
    "    name.append(i.text.replace('[',\" \").replace(']',' ').rstrip(''))\n",
    "                \n",
    "Rank=driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]/tbody/tr/td[1]\")\n",
    "for i in Rank:\n",
    "    rank.append(i.text.rstrip(\".\"))\n",
    "    \n",
    "Artist = driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]/tbody/tr/td[3]\")\n",
    "for i in Artist:\n",
    "    artist.append(i.text)\n",
    "        \n",
    "Date = driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]/tbody/tr/td[5]\")\n",
    "for i in Date:\n",
    "    date.append(i.text)\n",
    "    \n",
    "Views = driver.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]/tbody/tr/td[4]\")\n",
    "for i in Views:\n",
    "    views.append(i.text)\n",
    "    \n",
    "driver.quit()   \n",
    "#print(len(Name),len(Year),len(Genre),len(Run_time),len(Ratings),len(Votes))\n",
    "\n",
    "#Saving in dataframe            \n",
    "df=pd.DataFrame({'Name': name,\n",
    "                 'Rank':rank,\n",
    "                 'Artist':artist,\n",
    "                 'Date' : date,\n",
    "                 'Views':views})\n",
    "print(df)\n",
    "df.to_csv('youtube.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Title               Date       Time  \\\n",
      "0  1st ODI  Tuesday,23,MARCH,  13:30 IST   \n",
      "1  2nd ODI   Friday,26,MARCH,  13:30 IST   \n",
      "2  3rd ODI   Sunday,28,MARCH,  13:30 IST   \n",
      "\n",
      "                                           Place                Series  \n",
      "0  Maharashtra Cricket Association Stadium, Pune  INDIA V ENGLAND 2021  \n",
      "1  Maharashtra Cricket Association Stadium, Pune  INDIA V ENGLAND 2021  \n",
      "2  Maharashtra Cricket Association Stadium, Pune  INDIA V ENGLAND 2021  \n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get('https://www.bcci.tv/')\n",
    "time.sleep(3)\n",
    "\n",
    "#Click on International\n",
    "driver.find_element_by_xpath('/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]').click()\n",
    "time.sleep(3)\n",
    "#Click on Fixtures\n",
    "driver.find_element_by_xpath('/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a').click()\n",
    "time.sleep(2)\n",
    "#Click on 'matches in' arrow button\n",
    "driver.find_element_by_xpath('//*[@id=\"TestAlexFilter\"]').click()\n",
    "time.sleep(2)\n",
    "#Click on ODI\n",
    "driver.find_element_by_xpath('/html/body/div[4]/div/div/div[2]/div/div/div[3]/div/div[2]/div/ul/li[4]/span').click()\n",
    "time.sleep(2)\n",
    "\n",
    "#Creating empty list\n",
    "title,series,place,date,time = [],[],[],[],[]\n",
    "\n",
    "#Scrape required details\n",
    "Place=driver.find_elements_by_xpath(\"/html/body/div[4]/div/div/div[2]/section/div/div/a/div[2]/div[2]/p/span\")\n",
    "for i in Place:\n",
    "    place.append(i.text)\n",
    "    \n",
    "Time=driver.find_elements_by_xpath(\"/html/body/div[4]/div/div/div[2]/section/div/div/a/div[1]/div/div/span[2]\")\n",
    "for i in Time:\n",
    "    time.append(i.text)\n",
    "\n",
    "Title=driver.find_elements_by_xpath(\"/html/body/div[4]/div/div/div[2]/section/div/div/a/div[2]/div[2]/p/strong\")\n",
    "for i in Title:\n",
    "    title.append(i.text)\n",
    "\n",
    "Series=driver.find_elements_by_xpath('/html/body/div[4]/div/div/div[2]/section/div/div/a/div[2]/div[1]/span[2]')\n",
    "for i in Series:\n",
    "    series.append(i.text)\n",
    "    \n",
    "Date=driver.find_elements_by_xpath(\"//div[@class='fixture__datetime desktop-only']\") \n",
    "for i in Date:\n",
    "    date.append(i.text.replace('\\n',',').rstrip(\"13:30 IST\"))\n",
    "    \n",
    "driver.quit()   \n",
    "#print(len(title),len(place),len(date),len(time),len(series))\n",
    "#Saving in dataframe            \n",
    "df=pd.DataFrame({'Title': title,\n",
    "                 'Date':date,\n",
    "                 'Time':time,\n",
    "                 'Place' : place,\n",
    "                 'Series':series})\n",
    "print(df)\n",
    "df.to_csv('bcci.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Exception Name  \\\n",
      "0            ElementNotVisibleException   \n",
      "1         ElementNotSelectableException   \n",
      "2                NoSuchElementException   \n",
      "3                  NoSuchFrameException   \n",
      "4               NoAlertPresentException   \n",
      "5                 NoSuchWindowException   \n",
      "6        StaleElementReferenceException   \n",
      "7              SessionNotFoundException   \n",
      "8                      TimeoutException   \n",
      "9                    WebDriverException   \n",
      "10            ConnectionClosedException   \n",
      "11     ElementClickInterceptedException   \n",
      "12      ElementNotInteractableException   \n",
      "13             ErrorInResponseException   \n",
      "14  ErrorHandler.UnknownServerException   \n",
      "15         ImeActivationFailedException   \n",
      "16             ImeNotAvailableException   \n",
      "17         InsecureCertificateException   \n",
      "18             InvalidArgumentException   \n",
      "19         InvalidCookieDomainException   \n",
      "20          InvalidCoordinatesException   \n",
      "21          InvalidElementStateExceptio   \n",
      "22            InvalidSessionIdException   \n",
      "23       InvalidSwitchToTargetException   \n",
      "24                  JavascriptException   \n",
      "25                        JsonException   \n",
      "26             NoSuchAttributeException   \n",
      "27       MoveTargetOutOfBoundsException   \n",
      "28               NoSuchContextException   \n",
      "29                NoSuchCookieException   \n",
      "30                    NotFoundException   \n",
      "31          RemoteDriverServerException   \n",
      "32                  ScreenshotException   \n",
      "33           SessionNotCreatedException   \n",
      "34           UnableToSetCookieException   \n",
      "35           UnexpectedTagNameException   \n",
      "36              UnhandledAlertException   \n",
      "37      UnexpectedAlertPresentException   \n",
      "38               UnknownMethodException   \n",
      "39          UnreachableBrowserException   \n",
      "40          UnsupportedCommandException   \n",
      "\n",
      "                                          Description  \n",
      "0   This type of Selenium exception occurs when an...  \n",
      "1   This Selenium exception occurs when an element...  \n",
      "2   This Exception occurs if an element could not ...  \n",
      "3   This Exception occurs if the frame target to b...  \n",
      "4   This Exception occurs when you switch to no pr...  \n",
      "5   This Exception occurs if the window target to ...  \n",
      "6   This Selenium exception occurs happens when th...  \n",
      "7   The WebDriver is acting after you quit the bro...  \n",
      "8   Thrown when there is not enough time for a com...  \n",
      "9   This Exception takes place when the WebDriver ...  \n",
      "10  This type of Exception takes place when there ...  \n",
      "11  The command may not be completed as the elemen...  \n",
      "12  This Selenium exception is thrown when any ele...  \n",
      "13  This happens while interacting with the Firefo...  \n",
      "14  Exception is used as a placeholder in case if ...  \n",
      "15  This expectation will occur when IME engine ac...  \n",
      "16    It takes place when IME support is unavailable.  \n",
      "17  Navigation made the user agent to hit a certif...  \n",
      "18  It occurs when an argument does not belong to ...  \n",
      "19  This happens when you try to add a cookie unde...  \n",
      "20  This type of Exception matches an interacting ...  \n",
      "21  It occurs when command can't be finished when ...  \n",
      "22  This Exception took place when the given sessi...  \n",
      "23  This occurs when the frame or window target to...  \n",
      "24  This issue occurs while executing JavaScript g...  \n",
      "25  It occurs when you afford to get the session w...  \n",
      "26  This kind of Exception occurs when the attribu...  \n",
      "27  It takes place if the target provided to the A...  \n",
      "28           ContextAware does mobile device testing.  \n",
      "29  This Exception occurs when no cookie matching ...  \n",
      "30  This Exception is a subclass of WebDriverExcep...  \n",
      "31  This Selenium exception is thrown when the ser...  \n",
      "32            It is not possible to capture a screen.  \n",
      "33  It happens when a new session could not be suc...  \n",
      "34  This occurs if a driver is unable to set a coo...  \n",
      "35  Happens if a support class did not get a web e...  \n",
      "36  This expectation occurs when there is an alert...  \n",
      "37  It occurs when there is the appearance of an u...  \n",
      "38  This Exception happens when the requested comm...  \n",
      "39  This Exception occurs only when the browser is...  \n",
      "40  This occurs when remote WebDriver does n't sen...  \n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get('https://www.guru99.com/')\n",
    "time.sleep(3)\n",
    "\n",
    "#Click on selenium\n",
    "driver.find_element_by_xpath('/html/body/div[2]/section[4]/div/div/div/div/div/div/div/div[1]/div/ul[1]/li[3]/a').click()\n",
    "\n",
    "#Scroll to target location\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "target = driver.find_element_by_xpath('/html/body/div[2]/section[3]/div/div[1]/main/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[2]')\n",
    "target.location_once_scrolled_into_view \n",
    "time.sleep(3)\n",
    "\n",
    "#Click on Selenium Exception  \n",
    "driver.find_element_by_xpath('/html/body/div[2]/section[3]/div/div[1]/main/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[1]/a/strong').click()\n",
    "time.sleep(3)\n",
    "\n",
    "#Scroll to target location \n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "target = driver.find_element_by_xpath('/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/h2[1]')\n",
    "target.location_once_scrolled_into_view \n",
    "time.sleep(3)\n",
    "\n",
    "#empty list\n",
    "name,desc=[],[]\n",
    "\n",
    "#loop to scrape details \n",
    "for i in driver.find_elements_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/table/tbody/tr/td[1]\"):\n",
    "    if i.text is None :\n",
    "        name.append(\"--\") \n",
    "    else:\n",
    "        name.append(i.text)\n",
    "               \n",
    "for i in driver.find_elements_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/table/tbody/tr/td[2]\"):\n",
    "    if i.text is None :\n",
    "        desc.append(\"--\") \n",
    "    else:\n",
    "        desc.append(i.text)\n",
    "\n",
    "driver.quit()\n",
    "#print(len(name),len(desc))\n",
    "#Saving in Dataframe\n",
    "df=pd.DataFrame({'Exception Name':name[1:],\n",
    "                 'Description':desc[1:]})\n",
    "\n",
    "print(df)\n",
    "df.to_csv(\"exception.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4.Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ \n",
    "You have to find following details:\n",
    "A) Rank \n",
    "B) State \n",
    "C) GSDP(18-19) \n",
    "D) GSDP(17-18)\n",
    "E) Share(2017) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get('http://statisticstimes.com/')\n",
    "time.sleep(3)\n",
    "\n",
    "rank,state,gsdp(18-19),gsdp(17-18),share,gdp =[],[],[],[],[],[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap\"}\n  (Session info: chrome=88.0.4324.150)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-2ecaf911aa4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Click for Explore option\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#/html/body/div[1]/header/div[3]/nav/a[4]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DataScience\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_class_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \"\"\"\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DataScience\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mC:\\DataScience\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\DataScience\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap\"}\n  (Session info: chrome=88.0.4324.150)\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get('https://github.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "#Click for Explore option\n",
    "driver.find_element_by_class_name('Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap').click()\n",
    "time.sleep(2)\n",
    "#/html/body/div[1]/header/div[3]/nav/a[4]\n",
    "\n",
    "#Click for trending option\n",
    "driver.find_element_by_xpath('//div[@class=\"site-subnav bg-white site-subnav-sticky js-sticky\"]/nav/div/a[3]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "title,desc,count,lang =[],[],[],[]\n",
    "#loop to scrape details \n",
    "for i in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\"):\n",
    "    title.append(i.get_attribute('href'))\n",
    "               \n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='f6 text-gray mt-2']span\"):\n",
    "    lang.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='col-9 text-gray my-1 pr-4']\"):\n",
    "    desc.append(i.text)\n",
    "    \n",
    "#locating Ratings                                \n",
    "urls=driver.find_elements_by_xpath(\"//article[@class='Box-row']/h1/a\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:25]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        Count=driver.find_elements_by_xpath(\"/html/body/div[4]/div/main/div[2]/div/div[2]/div[2]/div/div[4]/div/h2/a/span']\")\n",
    "        count.append(Count.text)\n",
    "    except NoSuchElementException   as e:\n",
    "        count.append(\"NO count\")\n",
    "\n",
    "driver.quit()\n",
    "print(len(title),len(desc),len(count),len(lang))\n",
    "df=pd.DataFrame({'Repository Title':title,\n",
    "                 'Repository Description':desc,\n",
    "                 'Contributors Count':count,\n",
    "                 'Language used':lang,\n",
    "                 })\n",
    "               \n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6.Scrape the details of top 100 songs on billiboard.com. Url = https://www.billiboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Song Name                                Artist Name Last week  \\\n",
      "0  Drivers License                             Olivia Rodrigo         1   \n",
      "1             Mood               24kGoldn Featuring iann dior         1   \n",
      "2  Blinding Lights                                 The Weeknd         1   \n",
      "3            34+35                              Ariana Grande         2   \n",
      "4       Levitating                  Dua Lipa Featuring DaBaby         5   \n",
      "5         Go Crazy                   Chris Brown & Young Thug         5   \n",
      "6        Positions                              Ariana Grande         1   \n",
      "7  Save Your Tears                                 The Weeknd        14   \n",
      "8             Holy  Justin Bieber Featuring Chance The Rapper         3   \n",
      "9          Whoopty                                         CJ        16   \n",
      "\n",
      "  Peak rank Weeks  \n",
      "0         1        \n",
      "1        26     1  \n",
      "2        61     1  \n",
      "3        14     4  \n",
      "4        18     2  \n",
      "5        39     1  \n",
      "6        15    26  \n",
      "7         8     3  \n",
      "8        20     1  \n",
      "9        10    61  \n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get('https://www.billboard.com/')\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/header/div/ul/li[1]/a').click()\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/main/div[2]/div/div[1]/a/div[2]/div[2]/div[1]').click()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "target = driver.find_element_by_xpath('/html/body/main/div/div/div[7]/div/ol')\n",
    "target.location_once_scrolled_into_view \n",
    "time.sleep(2)\n",
    "\n",
    "name,artist,last_rank,peak_rank,weeks = [],[],[],[],[]\n",
    "#Scrape required details from each laptop\n",
    " \n",
    "for i in driver.find_elements_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li/button/span[2]/span[1]\"):\n",
    "    name.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li/button/span[2]/span[2]\"):\n",
    "    artist.append(i.text)\n",
    "     \n",
    "for i in driver.find_elements_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li/button/div/div[2]\"):\n",
    "    last_rank.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li/button/div/div[3]\"):\n",
    "    peak_rank.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"/html/body/main/div/div/div[7]/div/ol/li/button/div/div\"):\n",
    "    weeks.append(i.text)\n",
    "\n",
    "driver.quit()\n",
    "#print(len(name),len(artist),len(last_rank),len(peak_rank),len(weeks))\n",
    "df=pd.DataFrame({'Song Name':name[:100],\n",
    "                 'Artist Name':artist[:100],\n",
    "                 'Last week':last_rank[:100],\n",
    "                 'Peak rank':peak_rank[:100],\n",
    "                 'Weeks':weeks[:100]})\n",
    "\n",
    "print(df.head(10))\n",
    "df.to_csv(\"Billboard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7.Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\"}\n  (Session info: chrome=88.0.4324.150)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-b42703511f89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='skill']\"))).send_keys(\"Data Science\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Science\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DataScience\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DataScience\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mC:\\DataScience\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\DataScience\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\"}\n  (Session info: chrome=88.0.4324.150)\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com/')\n",
    "time.sleep(3)\n",
    "\n",
    "name,designation,company,skills,location = [],[],[],[],[]\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/ul[1]/li[2]/a/div').click()\n",
    "time.sleep(3)\n",
    "\n",
    "#driver.switch_to.window('hr-recruiters-consultants');\n",
    "\n",
    "\n",
    "#WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='skill']\"))).send_keys(\"Data Science\")\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\").send_keys(\"Data Science\")\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking the search button\n",
    "#WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@id='qsbFormBtn']\"))).click()\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"qsbFormBtn\"]').click()\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8.Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Book Name       Author Name  \\\n",
      "0                                   Da Vinci Code,The        Brown, Dan   \n",
      "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
      "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
      "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
      "4                                Fifty Shades of Grey      James, E. L.   \n",
      "..                                                ...               ...   \n",
      "95                                          Ghost,The    Harris, Robert   \n",
      "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
      "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
      "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
      "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
      "\n",
      "   Volumes Sold        Publisher                        Genre  \n",
      "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
      "1     4,475,152       Bloomsbury           Children's Fiction  \n",
      "2     4,200,654       Bloomsbury           Children's Fiction  \n",
      "3     4,179,479       Bloomsbury           Children's Fiction  \n",
      "4     3,758,936     Random House              Romance & Sagas  \n",
      "..          ...              ...                          ...  \n",
      "95      807,311     Random House   General & Literary Fiction  \n",
      "96      794,201          Penguin        Food & Drink: General  \n",
      "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
      "98      791,507            Orion           Biography: General  \n",
      "99      791,095          Penguin        Food & Drink: General  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "target = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[2]/div/div[2]/h2[1]')\n",
    "target.location_once_scrolled_into_view \n",
    "time.sleep(2)\n",
    "\n",
    "#soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#for tr in soup.find(class_=\"in-article sortable\").find_all(\"tr\"):\n",
    "#    data = [item.get_text(strip=True) for item in tr.find_all([\"th\",\"td\"])]\n",
    "#    print(data)\n",
    "\n",
    "b_name,a_name,vol_sold,publisher,genre= [],[],[],[],[]                                                                                                                 \n",
    "for i in driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[2]'):\n",
    "    b_name.append(i.text)\n",
    "                \n",
    "for i in driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[3]'):\n",
    "    a_name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[4]'):\n",
    "    vol_sold.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[5]'):\n",
    "    publisher.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[6]'):\n",
    "    genre.append(i.text)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df=pd.DataFrame({'Book Name' : b_name,\n",
    "                 'Author Name' : a_name,\n",
    "                 'Volumes Sold' : vol_sold,\n",
    "                 'Publisher' : publisher,\n",
    "                 'Genre' : genre })\n",
    "print(df)\n",
    "df.to_csv('guru99.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Name         Year                     Genre  \\\n",
      "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
      "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
      "2                 The Walking Dead     (2010– )   Drama, Horror, Thriller   \n",
      "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
      "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
      "..                             ...          ...                       ...   \n",
      "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
      "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
      "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
      "98           Scream: The TV Series  (2015–2019)      Crime, Drama, Horror   \n",
      "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
      "\n",
      "   Run_time Ratings      Votes  \n",
      "0    57 min     9.3  1,769,018  \n",
      "1    51 min     8.7    821,447  \n",
      "2    44 min     8.2    852,986  \n",
      "3    60 min     7.6    256,085  \n",
      "4    43 min     7.6    216,301  \n",
      "..      ...     ...        ...  \n",
      "95   42 min     7.5     43,563  \n",
      "96   50 min     7.8     53,845  \n",
      "97   42 min     8.1    161,082  \n",
      "98   45 min     7.2     34,081  \n",
      "99  572 min     8.6    182,161  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "time.sleep(3)\n",
    "\n",
    "imdb_dict = {}\n",
    "imdb_dict['Name']= []\n",
    "imdb_dict['Year']= []\n",
    "imdb_dict['Genre']= []\n",
    "imdb_dict['Run_time']= []\n",
    "imdb_dict['Ratings']= []\n",
    "imdb_dict['Votes']= []\n",
    "\n",
    "#Scrape required details from each laptop\n",
    "name = driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "for i in name:\n",
    "    imdb_dict['Name'].append(i.text)\n",
    "                \n",
    "year=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
    "for i in year:\n",
    "    imdb_dict['Year'].append(i.text)\n",
    "    \n",
    "genre = driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[5]\")\n",
    "for i in genre:\n",
    "    imdb_dict['Genre'].append(i.text)\n",
    "        \n",
    "run_time = driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[3]\")\n",
    "for i in run_time:\n",
    "    imdb_dict['Run_time'].append(i.text)\n",
    "    \n",
    "ratings = driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "for i in ratings:\n",
    "    imdb_dict['Ratings'].append(i.text)\n",
    "    \n",
    "votes = driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "for i in votes:\n",
    "    imdb_dict['Votes'].append(i.text)\n",
    "    \n",
    "driver.close()   \n",
    "#print(len(Name),len(Year),len(Genre),len(Run_time),len(Ratings),len(Votes))\n",
    "#Saving in dataframe            \n",
    "imdb_df=pd.DataFrame(imdb_dict)\n",
    "print(imdb_df)\n",
    "imdb_df.to_csv('imdb.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Dataset Name      Data Type               Attribute Type  \\\n",
      "0                         Adult  Multivariate   Categorical, Integer, Real    \n",
      "1                     Annealing  Multivariate         Categorical, Integer    \n",
      "2  Anonymous Microsoft Web Data  Multivariate   Categorical, Integer, Real    \n",
      "3                    Arrhythmia                                Categorical    \n",
      "4         Artificial Characters  Multivariate   Categorical, Integer, Real    \n",
      "5          Audiology (Original)  Multivariate   Categorical, Integer, Real    \n",
      "6      Audiology (Standardized)  Multivariate                  Categorical    \n",
      "7                      Auto MPG  Multivariate                  Categorical    \n",
      "8                    Automobile  Multivariate            Categorical, Real    \n",
      "9                        Badges  Multivariate   Categorical, Integer, Real    \n",
      "\n",
      "                   Task   Year Instances                   Attributes  \n",
      "0       Classification   1995      4177   Categorical, Integer, Real   \n",
      "1       Classification   1996     48842         Categorical, Integer   \n",
      "2       Classification              798   Categorical, Integer, Real   \n",
      "3  Recommender-Systems   1998     37711                  Categorical   \n",
      "4       Classification   1998       452   Categorical, Integer, Real   \n",
      "5       Classification   1992      6000   Categorical, Integer, Real   \n",
      "6       Classification   1987       226                  Categorical   \n",
      "7       Classification   1992       226                  Categorical   \n",
      "8           Regression   1993       398            Categorical, Real   \n",
      "9           Regression   1987       205   Categorical, Integer, Real   \n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\home\\chromedriver.exe\")\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b').click()\n",
    "time.sleep(3)    \n",
    "\n",
    "name,d_type,task,a_type,instances,attribute,year =[],[],[],[],[],[],[]\n",
    "\n",
    "#Scrape required details from each laptop\n",
    "Name = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "for i in Name:\n",
    "    if i.text is None :\n",
    "        name.append(\"--\")\n",
    "    else:\n",
    "        name.append(i.text)\n",
    "                \n",
    "Year=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]/p\")\n",
    "for i in Year:\n",
    "    if i.text is None :\n",
    "        year.append(\"--\")\n",
    "    else:\n",
    "        year.append(i.text)\n",
    "    \n",
    "D_type = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]/p\")\n",
    "for i in D_type:\n",
    "    if i.text is None :\n",
    "        d_type.append(\"--\")\n",
    "    else:\n",
    "        d_type.append(i.text)\n",
    "\n",
    "A_type = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]/p\")\n",
    "for i in A_type:\n",
    "    if i.text is None :\n",
    "        a_type.append(\"--\")\n",
    "    else:\n",
    "        a_type.append(i.text)\n",
    "        \n",
    "Task = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]/p\")\n",
    "for i in Task:\n",
    "    if i.text is None :\n",
    "        task.append(\"--\")\n",
    "    else:\n",
    "        task.append(i.text)\n",
    "    \n",
    "Instances = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]/p\")\n",
    "for i in Instances:\n",
    "    if i.text is None :\n",
    "        instances.append(\"--\")\n",
    "    else:\n",
    "        instances.append(i.text)\n",
    "    \n",
    "Attribute = driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]/p\")\n",
    "for i in Attribute:\n",
    "    if i.text is None :\n",
    "        attribute.append(\"--\")\n",
    "    else:\n",
    "        attribute.append(i.text)\n",
    "\n",
    "driver.quit()\n",
    "#print(len(name),len(d_type),len(year),len(instances),len(attribute),len(task),len(a_type),len(d_type))\n",
    "\n",
    "df=pd.DataFrame({'Dataset Name':name[1:100],\n",
    "                 'Data Type':d_type[1:100],\n",
    "                 'Attribute Type':a_type[1:100],\n",
    "                 'Task':task[1:100],\n",
    "                 'Year':year[1:100],\n",
    "                 'Instances':instances[1:100],\n",
    "                 'Attributes':attribute[1:100]})\n",
    "\n",
    "print(df.head(10))\n",
    "df.to_csv(\"Dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
